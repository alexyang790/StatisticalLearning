---
title: "Homework #6: SVM and Calibration" 
author: "**Your Name Here**"
format: ds6030hw-html
---

```{r config, include=FALSE}
# Set global configurations and settings here
knitr::opts_chunk$set()                 # set global chunk options
ggplot2::theme_set(ggplot2::theme_bw()) # set ggplot2 theme
```

# Required R packages and Directories {.unnumbered .unlisted}

```{r packages, message=FALSE, warning=FALSE}
dir_data= 'https://mdporter.github.io/teaching/data/' # data directory
library(tidyverse)  # functions for data manipulation  
```


# COMPAS Recidivism Prediction

A recidivism risk model called COMPAS was the topic of a [ProPublica article](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing/) on ML bias. Because the data and notebooks used for article was released on [github](https://github.com/propublica/compas-analysis), we can also evaluate the prediction bias (i.e., calibration). 

This code will read in the *violent crime* risk score and apply the filtering used in the [analysis](https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb).
```{r, message=FALSE}
#| code-fold: true
library(tidyverse)
df = read_csv("https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years-violent.csv")

risk = df %>% 
  filter(days_b_screening_arrest <= 30) %>%
  filter(days_b_screening_arrest >= -30) %>% 
  filter(is_recid != -1) %>%
  filter(c_charge_degree != "O") %>%
  filter(v_score_text != 'N/A') %>% 
  transmute(
    age, age_cat,
    charge = ifelse(c_charge_degree == "F", "Felony", "Misdemeanor"),
    race,
    sex,                 
    priors_count = priors_count...15,
    score = v_decile_score,              # the risk score {1,2,...,10}
    outcome = two_year_recid...53        # outcome {1 = two year recidivate}
  )
```

The `risk` data frame has the relevant information for completing the problems.



# Problem 1: COMPAS risk score


## a. Risk Score and Probability (table)

Assess the predictive bias in the COMPAS risk scores by evaluating the probability of recidivism, e.g. estimate $\Pr(Y = 1 \mid \text{Score}=x)$. Use any reasonable techniques (including Bayesian) to estimate the probability of recidivism for each risk score. 

Specifically, create a table (e.g., data frame) that provides the following information:

- The COMPASS risk score.
- The point estimate of the probability of recidivism for each risk score.
- 95% confidence or credible intervals for the probability (e.g., Using normal theory, bootstrap, or Bayesian techniques).

Indicate the choices you made in estimation (e.g., state the prior if you used Bayesian methods).

::: {.callout-note title="Solution"}
```{r}
library(tidyverse)
library(broom)

risk_analysis <- risk %>%
  group_by(score) %>%
  summarise(
    n = n(),
    recid_prob = mean(outcome),
    se = sqrt(recid_prob * (1 - recid_prob) / n)
  ) %>%
  mutate(
    ci_lower = recid_prob - 1.96 * se,
    ci_upper = recid_prob + 1.96 * se
  ) %>%
  select(score, n, recid_prob, ci_lower, ci_upper)

print(risk_analysis)
```
> For the confidence interval I used the normal approximatio methods and assumed that the samping distribution is approximately normal given the large sample size

:::

## b. Risk Score and Probability (plot)

Make a plot of the risk scores and corresponding estimated probability of recidivism. 

- Put the risk score on the x-axis and estimate probability of recidivism on y-axis.
- Add the 95% confidence or credible intervals calculated in part a.
- Comment on the patterns you see. 

::: {.callout-note title="Solution"}
```{r}
ggplot(risk_analysis, aes(x = score, y = recid_prob)) +
  geom_point(size = 2, color = "red") +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) +
  geom_line(color = "blue") +
  scale_x_continuous(breaks = 1:10) +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
  labs(
    title = "COMPAS Score vs Recidivism Probability",
    x = "COMPAS Risk Score",
    y = "Recidivism Probability"
  ) +
  theme_minimal()

```
> there is a positive correlation between the COMPAS score and the estimated probability of recidivism. However the relationship is not perfectly linear. This indicates that there might be some calibration issues because the probabilities don't align perfectly with what the risk score might suggest, espeically between ruisk score 9 and 10 we can see a significant difference between the two. Looking at the confidence intervals we can see there are few overlaps between different COMPAS risk scores which might suggested more errors in the scores. 
:::

## c. Risk Score and Probability (by race)

Repeat the analysis, but this time do so for every race. Produce a set of plots (one per race) and comment on the patterns. 


::: {.callout-note title="Solution"}
```{r}
risk_analysis_by_race <- risk %>%
  group_by(race, score) %>%
  summarise(
    n = n(),
    recid_prob = mean(outcome),
    se = sqrt(recid_prob * (1 - recid_prob) / n)
  ) %>%
  mutate(
    ci_lower = pmax(0, recid_prob - 1.96 * se),
    ci_upper = pmin(1, recid_prob + 1.96 * se)
  ) %>%
  ungroup()


ggplot(risk_analysis_by_race, aes(x = score, y = recid_prob)) +
  geom_point(size = 2, color = "red") +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) +
  geom_line(color = "blue") +
  facet_wrap(~ race, scales = "free_y") +
  scale_x_continuous(breaks = seq(1, 10, by = 2)) +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent_format(accuracy = 1)) +
  labs(
    title = "COMPAS Score vs Recidivism Probability by Race",
    x = "COMPAS Risk Score",
    y =  "Recidivism Probability",
  ) +
  theme_minimal() 
```
> first we can see that there isn't much data for races other than African Americans and Caucasian beacuse these two races have the narrowest confidence intervals compared to other races. Second there is very inconsistent patterns for Asian, Hispanic, and Native Americans which suggests discrimination based on races. 
:::

## d. ROC Curves

Use the raw COMPAS risk scores to make a ROC curve for each race. 

- Are the best discriminating models the ones you expected? 
- Are the ROC curves helpful in evaluating the COMPAS risk score? 

::: {.callout-note title="Solution"}
```{r}
library(pROC)

create_roc_curve <- function(data, race_group) {
  race_data <- data %>% filter(race == race_group)
  roc_obj <- roc(race_data$outcome, race_data$score)
  auc_value <- auc(roc_obj)
  
  list(roc = roc_obj, auc = auc_value)
}

races <- unique(risk$race)
roc_results <- map(races, ~create_roc_curve(risk, .))
names(roc_results) <- races

plot(roc_results[[1]]$roc, main="ROC Curves by Race", col=1)
for (i in 2:length(roc_results)) {
  plot(roc_results[[i]]$roc, add=TRUE, col=i)
}
legend("bottomright", legend=races, col=1:length(races), lwd=2)
```
> yes the best discriminating models are the ones i expected which is the races other than white and african american. The ROC curve is helpfull because they show the differences in model performance across different racial groups in one graph
:::


# Problem 2: Support Vector Machines (SVM)

Focus on Problem 1, we won't have an SVM problem this week.



    

